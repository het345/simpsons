{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import caer\n",
    "import canaro\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (80,80)\n",
    "channels = 1\n",
    "char_path = '/Users/hetan2/Desktop/simpsons /archive/simpsons_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('homer_simpson', 2246),\n",
       " ('ned_flanders', 1454),\n",
       " ('moe_szyslak', 1452),\n",
       " ('lisa_simpson', 1354),\n",
       " ('bart_simpson', 1342),\n",
       " ('marge_simpson', 1291),\n",
       " ('krusty_the_clown', 1206),\n",
       " ('principal_skinner', 1194),\n",
       " ('charles_montgomery_burns', 1193),\n",
       " ('milhouse_van_houten', 1079),\n",
       " ('chief_wiggum', 986),\n",
       " ('abraham_grampa_simpson', 913),\n",
       " ('sideshow_bob', 877),\n",
       " ('apu_nahasapeemapetilon', 623),\n",
       " ('kent_brockman', 498),\n",
       " ('comic_book_guy', 469),\n",
       " ('edna_krabappel', 457),\n",
       " ('nelson_muntz', 358),\n",
       " ('lenny_leonard', 310),\n",
       " ('mayor_quimby', 246),\n",
       " ('waylon_smithers', 181),\n",
       " ('maggie_simpson', 128),\n",
       " ('groundskeeper_willie', 121),\n",
       " ('barney_gumble', 106),\n",
       " ('selma_bouvier', 103),\n",
       " ('carl_carlson', 98),\n",
       " ('ralph_wiggum', 89),\n",
       " ('patty_bouvier', 72),\n",
       " ('martin_prince', 71),\n",
       " ('professor_john_frink', 65),\n",
       " ('snake_jailbird', 55),\n",
       " ('cletus_spuckler', 47),\n",
       " ('rainier_wolfcastle', 45),\n",
       " ('simpsons_dataset', 42),\n",
       " ('agnes_skinner', 42),\n",
       " ('sideshow_mel', 40),\n",
       " ('otto_mann', 32),\n",
       " ('fat_tony', 27),\n",
       " ('gil', 27),\n",
       " ('miss_hoover', 17),\n",
       " ('troy_mcclure', 8),\n",
       " ('disco_stu', 8),\n",
       " ('lionel_hutz', 3)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict ={}\n",
    "for char in os.listdir(char_path):\n",
    "    char_dict[char] = len(os.listdir(os.path.join(char_path,char)))\n",
    "char_dict = caer.sort_dict(char_dict, descending= True)\n",
    "char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homer_simpson',\n",
       " 'ned_flanders',\n",
       " 'moe_szyslak',\n",
       " 'lisa_simpson',\n",
       " 'bart_simpson',\n",
       " 'marge_simpson',\n",
       " 'krusty_the_clown',\n",
       " 'principal_skinner',\n",
       " 'charles_montgomery_burns',\n",
       " 'milhouse_van_houten']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = []\n",
    "count = 0\n",
    "for i in char_dict:\n",
    "    characters.append(i[0])\n",
    "    count+=1\n",
    "    if count>=10:\n",
    "        break\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Could not find a file to load from. Generating the training data\n",
      "----------------------------------------------\n",
      "[INFO] At 1000 files\n",
      "[INFO] At 2000 files\n",
      "[INFO] 2246 files found in 0.002894163131713867s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1454 files found in 0.001605987548828125s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1452 files found in 0.0014469623565673828s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1354 files found in 0.0013129711151123047s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1342 files found in 0.0012941360473632812s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1291 files found in 0.0013229846954345703s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1206 files found in 0.001125335693359375s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1194 files found in 0.0011088848114013672s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1193 files found in 0.0011298656463623047s\n",
      "[INFO] At 1000 files\n",
      "[INFO] 1079 files found in 0.0010302066802978516s\n",
      "----------------------------------------------\n",
      "[INFO] 13811 files preprocessed! Took 0m 10s\n"
     ]
    }
   ],
   "source": [
    "# create training data\n",
    "train = caer.preprocess_from_dir(char_path, characters, channels= channels, IMG_SIZE=IMG_SIZE, isShuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13811"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "#normalize the featureSet (0,1)\n",
    "featureSet = caer.normalize(featureSet)\n",
    "labels = to_categorical(labels, len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = caer.train_val_split(featureSet, labels, val_ratio=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del featureSet\n",
    "del labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data generator\n",
    "datd_gen = canaro.generators.imageDataGenerator()\n",
    "train_gen = datd_gen.flow(x_train, y_train, batch_size =BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
